{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f251cf00",
   "metadata": {},
   "source": [
    "# MACHINE LEARING\n",
    "A notebook to implement machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094655b",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388e6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c2e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn modules in use\n",
    "\n",
    "# prepare test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# train and select models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "\n",
    "# cross-valiate model\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04481c2",
   "metadata": {},
   "source": [
    "**Note:** I will jump directly to the main dishes (pipelines and metrics) since the data cleaning and EDA have been caried already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fce28",
   "metadata": {},
   "source": [
    "# 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "129f1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "X_train = pd.read_csv('../dataset/X_train.csv').drop(columns=['country'])\n",
    "y_train = pd.read_csv('../dataset/y_train.csv')\n",
    "\n",
    "X_test = pd.read_csv('../dataset/X_test.csv').drop(columns=['country'])\n",
    "y_test = pd.read_csv('../dataset/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ddd8c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>adult_mortality</th>\n",
       "      <th>infant_deaths</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>percentage_expenditure</th>\n",
       "      <th>hepatitis_b</th>\n",
       "      <th>measles</th>\n",
       "      <th>bmi</th>\n",
       "      <th>under_five_deaths</th>\n",
       "      <th>polio</th>\n",
       "      <th>...</th>\n",
       "      <th>thinness_5_9_years</th>\n",
       "      <th>income_composition_of_resources</th>\n",
       "      <th>schooling</th>\n",
       "      <th>status_Developed</th>\n",
       "      <th>status_Developing</th>\n",
       "      <th>continent_Africa</th>\n",
       "      <th>continent_Americas</th>\n",
       "      <th>continent_Asia</th>\n",
       "      <th>continent_Europe</th>\n",
       "      <th>continent_Oceania</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.232577</td>\n",
       "      <td>2.116288</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1307.890020</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4648</td>\n",
       "      <td>61.6</td>\n",
       "      <td>10</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.773</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.69</td>\n",
       "      <td>21.411235</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.597</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>99.080954</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>54.8</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>717.0</td>\n",
       "      <td>28</td>\n",
       "      <td>4.14</td>\n",
       "      <td>8.717409</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>420</td>\n",
       "      <td>27.5</td>\n",
       "      <td>43</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.406</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  adult_mortality  infant_deaths  alcohol  percentage_expenditure  \\\n",
       "0  2004            214.0              0     4.55                4.232577   \n",
       "1  2007             99.0              9     0.10             1307.890020   \n",
       "2  2006             17.0              3     3.69               21.411235   \n",
       "3  2010             19.0              0     5.26               99.080954   \n",
       "4  2005            717.0             28     4.14                8.717409   \n",
       "\n",
       "   hepatitis_b  measles   bmi  under_five_deaths  polio  ...  \\\n",
       "0     2.116288        0   5.4                  0   84.0  ...   \n",
       "1    96.000000     4648  61.6                 10   96.0  ...   \n",
       "2    88.000000        0  47.1                  4   88.0  ...   \n",
       "3    86.000000        0  54.8                  0   96.0  ...   \n",
       "4    65.000000      420  27.5                 43   69.0  ...   \n",
       "\n",
       "   thinness_5_9_years  income_composition_of_resources  schooling  \\\n",
       "0                 3.5                            0.000       11.1   \n",
       "1                 7.3                            0.773       12.7   \n",
       "2                 1.9                            0.597       11.0   \n",
       "3                 3.4                            0.700       12.3   \n",
       "4                 9.0                            0.406        9.3   \n",
       "\n",
       "   status_Developed  status_Developing  continent_Africa  continent_Americas  \\\n",
       "0                 0                  1                 0                   1   \n",
       "1                 0                  1                 0                   0   \n",
       "2                 0                  1                 0                   1   \n",
       "3                 0                  1                 0                   1   \n",
       "4                 0                  1                 1                   0   \n",
       "\n",
       "   continent_Asia  continent_Europe  continent_Oceania  \n",
       "0               0                 0                  0  \n",
       "1               1                 0                  0  \n",
       "2               0                 0                  0  \n",
       "3               0                 0                  0  \n",
       "4               0                 0                  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the training set\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ee191fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'adult_mortality', 'infant_deaths', 'alcohol',\n",
       "       'percentage_expenditure', 'hepatitis_b', 'measles', 'bmi',\n",
       "       'under_five_deaths', 'polio', 'total_expenditure', 'diphtheria',\n",
       "       'hiv/aids', 'gdp', 'population', 'thinness_10_19_years',\n",
       "       'thinness_5_9_years', 'income_composition_of_resources', 'schooling',\n",
       "       'status_Developed', 'status_Developing', 'continent_Africa',\n",
       "       'continent_Americas', 'continent_Asia', 'continent_Europe',\n",
       "       'continent_Oceania'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns of the data\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f42db",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f835f3",
   "metadata": {},
   "source": [
    "**Note:** The preprocessing (continent converter & dummy attributes) has been held. However, since the method includes clustering (especially by K-Means) & regularized linear regression, scaling will be a good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61eed2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "num_attrbs = ['year', 'adult_mortality', 'infant_deaths', 'alcohol',\n",
    "       'percentage_expenditure', 'hepatitis_b', 'measles', 'bmi',\n",
    "       'under_five_deaths', 'polio', 'total_expenditure', 'diphtheria',\n",
    "       'hiv/aids', 'gdp', 'population', 'thinness_10_19_years',\n",
    "       'thinness_5_9_years', 'income_composition_of_resources', 'schooling']\n",
    "\n",
    "scaler = ColumnTransformer([\n",
    "    (\"standard_scaler\", StandardScaler(), num_attrbs),\n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb320e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76476795,  0.40158706, -0.25556559, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.11180122, -0.53186527, -0.18124577, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.3294568 , -1.19745737, -0.23079232, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.4117878 , -0.1016655 , -0.18950353, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5411655 , -1.03511784,  0.18209561, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.76476795, -0.71043876, -0.23905008, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    (\"stad_scaler\", scaler)\n",
    "])\n",
    "\n",
    "X_prep = full_pipeline.fit_transform(X_train)\n",
    "X_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aabc8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the variable of interest\n",
    "y_prep = y_train # nothing to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0dcb4",
   "metadata": {},
   "source": [
    "# 4. Select and Train Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ca9eb",
   "metadata": {},
   "source": [
    "**Note:** In the first approach, we only use linear-relevant models such as SVM, Linear Regression and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f94c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show RMSE of a model\n",
    "def root_mean_squared_error(y, y_hat):\n",
    "    mse = mean_squared_error(y, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8424c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the score of cross validation\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53cae7",
   "metadata": {},
   "source": [
    "## 4.1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6d1274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a linear regressor\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_prep, y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efd8f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.025442305433962"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the training\n",
    "root_mean_squared_error(y_prep, lin_reg.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9cfd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [4.10500811 3.81847688 3.4580502  4.40698856 3.98350413 4.29550662\n",
      " 3.70116329 4.23798102 4.32449396 4.27712182]\n",
      "Mean: 4.060829459402693\n",
      "Standard deviation: 0.29697673964948745\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation on the model\n",
    "scores = np.sqrt(-cross_val_score(lin_reg, X_prep, y_prep, scoring=\"neg_mean_squared_error\", cv=10))\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbad75e",
   "metadata": {},
   "source": [
    "## 4.2. Clustered Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a605177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model of clustered Linear Regressions on clusters of K-Means\n",
    "class ClusteredLinearRegression(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 clusterer=KMeans(n_clusters=4, random_state=42), \n",
    "                 estimator=ElasticNet(alpha=0), \n",
    "                 classifier=None):\n",
    "        \n",
    "        self.clusterer = clusterer\n",
    "        self.estimator = estimator\n",
    "        self.classifier = classifier # if the clusterer cannot predict for the new instances\n",
    "       \n",
    "    def fit(self, X, y=None):\n",
    "        # cluster the data\n",
    "        self.clusterer.fit(X)\n",
    "        \n",
    "        # fit the data of each cluster using a elastic net\n",
    "        lin_regs = {}\n",
    "        clusters = np.unique(self.clusterer.labels_)\n",
    "        for cluster in clusters:\n",
    "            lin_reg = clone(self.estimator)\n",
    "            lin_reg.fit(X[self.clusterer.labels_ == cluster], y[self.clusterer.labels_ == cluster])\n",
    "            lin_regs[cluster] = lin_reg\n",
    "            \n",
    "        self.lin_regs_ = lin_regs\n",
    "        \n",
    "        # train classifier to classify the new instances (if needed)\n",
    "        if self.classifier != None:\n",
    "            self.classifier.fit(X, self.clusterer.labels_)\n",
    "        \n",
    "        return self.lin_regs_\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.clusterer.transform(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_hat = np.zeros(X.shape[0])\n",
    "        \n",
    "        # predict the cluster of new instances\n",
    "        if self.classifier != None:\n",
    "            clusters_pred = self.classifier.predict(X)\n",
    "        else:\n",
    "            clusters_pred = self.clusterer.predict(X)\n",
    "        \n",
    "        # predict the labels of new instances based on clusters\n",
    "        for cluster in self.lin_regs_.keys():\n",
    "            if X[clusters_pred == cluster].shape[0] > 0:\n",
    "                y_hat_cluster = self.lin_regs_[cluster].predict(X[clusters_pred == cluster])\n",
    "                y_hat[clusters_pred == cluster] = y_hat_cluster\n",
    "        \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b489e4",
   "metadata": {},
   "source": [
    "### 4.2.1. KMeans and Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ee4fc",
   "metadata": {},
   "source": [
    "**Note:** The linear-based strategy is to use KMeans as the clusterer and ElasticNet (LR) as the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9fb9c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ElasticNet(), 1: ElasticNet(), 2: ElasticNet(), 3: ElasticNet()}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a clusterd linear regressor\n",
    "lin_regs = ClusteredLinearRegression(clusterer=KMeans(n_clusters=4, random_state=42), \n",
    "                                     estimator=ElasticNet())\n",
    "lin_regs.fit(X_prep, y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d4432ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.938312264604737"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the training\n",
    "root_mean_squared_error(y_prep, lin_regs.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bedbac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [5.02244247 4.80598226 4.1638663  4.86888403 5.24965875 5.37413944\n",
      " 4.67774444 5.36423063 5.06702584 5.20334974]\n",
      "Mean: 4.979732389160712\n",
      "Standard deviation: 0.351427907749583\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation on the model\n",
    "scores = np.sqrt(-cross_val_score(lin_regs, X_prep, y_prep, scoring=\"neg_mean_squared_error\", \n",
    "                                  cv=10, error_score=\"raise\"))\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd76993",
   "metadata": {},
   "source": [
    "### 4.2.2. KMeans, Elastic Net and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee9d97ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ElasticNet(), 1: ElasticNet(), 2: ElasticNet(), 3: ElasticNet()}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a clustered linear regressor (with KNN)\n",
    "kmeans_lins_knn = ClusteredLinearRegression(clusterer=KMeans(n_clusters=4, random_state=42), \n",
    "                                           estimator=ElasticNet(), \n",
    "                                           classifier=KNeighborsClassifier())\n",
    "kmeans_lins_knn.fit(X_prep, y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "464db698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.91821472527952"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the training\n",
    "root_mean_squared_error(y_prep, kmeans_lins_knn.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa248efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [4.9879717  4.73217517 4.26984356 4.7768414  5.23016244 5.43161385\n",
      " 4.62100648 5.44751899 5.53747539 5.10687049]\n",
      "Mean: 5.014147947620382\n",
      "Standard deviation: 0.39195370364471704\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation on the model\n",
    "scores = np.sqrt(-cross_val_score(kmeans_lins_knn, X_prep, y_prep, scoring=\"neg_mean_squared_error\", \n",
    "                                  cv=10, error_score=\"raise\"))\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fba26",
   "metadata": {},
   "source": [
    "# 5. Fine-tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348bcd4",
   "metadata": {},
   "source": [
    "**Note:** Randomized Search is performed first to narrow down the search space, then Grid Search will be performed on that narrowed space. The result param could be optimal or not, but it is expected to construct a better model based on that param."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d125e30",
   "metadata": {},
   "source": [
    "## 5.1. Clustered Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06255d",
   "metadata": {},
   "source": [
    "### 5.1.1. KMeans and Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e221bd1",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb85780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "                   estimator=ClusteredLinearRegression(), n_iter=50,\n",
       "                   param_distributions={'clusterer__n_clusters': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD1CE2F400>,\n",
       "                                        'estimator__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD1CE3D460>,\n",
       "                                        'estimator__l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD178B7790>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform randomized search\n",
    "param_distribs = {\n",
    "    \"clusterer__n_clusters\": randint(low=1, high=50),\n",
    "    \"estimator__alpha\": uniform(loc=1e-4, scale=1),\n",
    "    \"estimator__l1_ratio\": uniform(loc=0.01, scale=0.09)\n",
    "}\n",
    "\n",
    "lins_rndsearch = RandomizedSearchCV(ClusteredLinearRegression(), param_distributions=param_distribs,\n",
    "                                     n_iter=50, cv=10, scoring='neg_mean_squared_error', \n",
    "                                     error_score=\"raise\", random_state=42)\n",
    "lins_rndsearch.fit(X_prep, y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03cb1ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 3.224143382222099\n",
      "Best param: {'clusterer__n_clusters': 42, 'estimator__alpha': 0.04676566321361543, 'estimator__l1_ratio': 0.09763799669573131}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate score\n",
    "cvres = lins_rndsearch.cv_results_\n",
    "min_loss = np.inf\n",
    "opt_param = None\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    if min_loss > np.sqrt(-mean_score):\n",
    "        min_loss = np.sqrt(-mean_score)\n",
    "        opt_param = params\n",
    "print(\"Best score:\", min_loss)\n",
    "print(\"Best param:\", opt_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "186de07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusteredLinearRegression(clusterer=KMeans(n_clusters=42, random_state=42),\n",
       "                          estimator=ElasticNet(alpha=0.04676566321361543,\n",
       "                                               l1_ratio=0.09763799669573131))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the best estimator\n",
    "lins_rndsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c179876",
   "metadata": {},
   "source": [
    "### 5.1.2. KMeans, ElasticNet and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "614f4992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "                   estimator=ClusteredLinearRegression(classifier=KNeighborsClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'classifier__n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD1CDB8EB0>,\n",
       "                                        'classifier__weights': ['distance'],\n",
       "                                        'clusterer__n_clusters': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD1CE5F9D0>,\n",
       "                                        'estimator__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD1789C7F0>,\n",
       "                                        'estimator__l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BD1CE3D880>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform randomized search\n",
    "param_distribs = {\n",
    "    \"clusterer__n_clusters\": randint(low=1, high=50),\n",
    "    \"estimator__alpha\": uniform(loc=1e-4, scale=1),\n",
    "    \"estimator__l1_ratio\": uniform(loc=0.01, scale=0.09),\n",
    "    \"classifier__n_neighbors\": randint(low=3, high=15),\n",
    "    \"classifier__weights\": [\"distance\"]\n",
    "}\n",
    "\n",
    "kmeans_lins_knn_rndsearch = RandomizedSearchCV(ClusteredLinearRegression(classifier=KNeighborsClassifier()), \n",
    "                                     param_distributions=param_distribs,\n",
    "                                     n_iter=50, cv=10, scoring='neg_mean_squared_error', \n",
    "                                     error_score=\"raise\", random_state=42)\n",
    "kmeans_lins_knn_rndsearch.fit(X_prep, y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4af8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 3.2030714717532476\n",
      "Best param: {'classifier__n_neighbors': 13, 'classifier__weights': 'distance', 'clusterer__n_clusters': 42, 'estimator__alpha': 0.04676566321361543, 'estimator__l1_ratio': 0.09763799669573131}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate score\n",
    "cvres = kmeans_lins_knn_rndsearch.cv_results_\n",
    "min_loss = np.inf\n",
    "opt_param = None\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    if min_loss > np.sqrt(-mean_score):\n",
    "        min_loss = np.sqrt(-mean_score)\n",
    "        opt_param = params\n",
    "print(\"Best score:\", min_loss)\n",
    "print(\"Best param:\", opt_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e00c0572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusteredLinearRegression(classifier=KNeighborsClassifier(n_neighbors=13,\n",
       "                                                          weights='distance'),\n",
       "                          clusterer=KMeans(n_clusters=42, random_state=42),\n",
       "                          estimator=ElasticNet(alpha=0.04676566321361543,\n",
       "                                               l1_ratio=0.09763799669573131))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the best estimator\n",
    "kmeans_lins_knn_rndsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2aca64",
   "metadata": {},
   "source": [
    "# 6. Evaluate the System on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff6b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall test set\n",
    "X_test_prep = full_pipeline.fit_transform(X_test)\n",
    "y_test_prep = y_test[\"life_expectancy\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2681fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display score\n",
    "def evaluate(y, y_hat):\n",
    "    print(\"RMSE: \", root_mean_squared_error(y, y_hat))\n",
    "    print(\"MAE: \", mean_absolute_error(y, y_hat))\n",
    "    print(\"R2: \", r2_score(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23182608",
   "metadata": {},
   "source": [
    "## 6.1. Clustered Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece02970",
   "metadata": {},
   "source": [
    "### 6.1.1. Kmeans and Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a49373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  5.004032507392436\n",
      "MAE:  3.735802185694426\n",
      "R2:  0.722892157774097\n"
     ]
    }
   ],
   "source": [
    "# Train a defaut\n",
    "lin_regs = ClusteredLinearRegression(clusterer=KMeans(), \n",
    "                                     estimator=ElasticNet())\n",
    "lin_regs.fit(X_prep, y_prep)\n",
    "evaluate(y_prep, lin_regs.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc581370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.6083772032732737\n",
      "MAE:  1.9278512753076302\n",
      "R2:  0.9247079080781789\n"
     ]
    }
   ],
   "source": [
    "# Retrain the pure clustered regressor\n",
    "final_kmeans_lins = ClusteredLinearRegression(clusterer=KMeans(n_clusters=42, random_state=42),\n",
    "                                              estimator=ElasticNet(alpha=0.04676566321361543, l1_ratio=0.09763799669573131))\n",
    "final_kmeans_lins.fit(X_prep, y_prep)\n",
    "evaluate(y_prep, final_kmeans_lins.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56265ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.2228855004965395\n",
      "MAE:  2.309741297732761\n",
      "R2:  0.8865192307843883\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "y_test_pred = final_kmeans_lins.predict(X_test_prep)\n",
    "evaluate(y_test_prep, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650cecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.87131977, 3.53970404])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute 95% confidence interval for generalization error (rmse only)\n",
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "\n",
    "squared_errors = (y_test_pred - y_test_prep) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors))) # t-distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8da80e",
   "metadata": {},
   "source": [
    "### 6.1.2. Kmeans, Elastic Net and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6fe6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4.997367945250951\n",
      "MAE:  3.7143473626913175\n",
      "R2:  0.7236297919163911\n"
     ]
    }
   ],
   "source": [
    "# Train a defaut\n",
    "kmeans_lins_knn = ClusteredLinearRegression(clusterer=KMeans(), \n",
    "                                           estimator=ElasticNet(), \n",
    "                                           classifier=KNeighborsClassifier())\n",
    "kmeans_lins_knn.fit(X_prep, y_prep)\n",
    "evaluate(y_prep, kmeans_lins_knn.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2d0217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.6083772032732737\n",
      "MAE:  1.9278512753076302\n",
      "R2:  0.9247079080781789\n"
     ]
    }
   ],
   "source": [
    "# Retrain the pure clustered regressor\n",
    "final_kmeans_lins_knn = ClusteredLinearRegression(classifier=KNeighborsClassifier(n_neighbors=13, weights='distance'),\n",
    "                                                  clusterer=KMeans(n_clusters=42, random_state=42),\n",
    "                                                  estimator=ElasticNet(alpha=0.04676566321361543, l1_ratio=0.09763799669573131))\n",
    "final_kmeans_lins_knn.fit(X_prep, y_prep)\n",
    "evaluate(y_prep, final_kmeans_lins_knn.predict(X_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb00679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.1814351000713206\n",
      "MAE:  2.289209747555816\n",
      "R2:  0.8894194732863653\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "y_test_pred = final_kmeans_lins_knn.predict(X_test_prep)\n",
    "evaluate(y_test_prep, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9800fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.85096809, 3.48066654])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute 95% confidence interval for generalization error (rmse only)\n",
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "\n",
    "squared_errors = (y_test_pred - y_test_prep) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors))) # t-distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
